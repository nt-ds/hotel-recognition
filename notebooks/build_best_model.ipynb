{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "build_best_model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1EaIOfUZPGI",
        "colab_type": "code",
        "outputId": "2dc7cbcb-192d-4243-f882-59f60edbe7ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oRD997yXINEq"
      },
      "source": [
        "# Hotels Against Trafficking\n",
        "Sep 11, 2019<br>\n",
        "Ngoc Tran\n",
        "\n",
        "---------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUEnQyER7NTE",
        "colab_type": "text"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcRm0ZE6Yft4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NakLcqpTbOD0",
        "colab_type": "text"
      },
      "source": [
        "Get the original directory:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DgnCRIJiOhe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "original_path = os.getcwd()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ta9M9WPH7XFJ",
        "colab_type": "text"
      },
      "source": [
        "Change directory to get the source code to build the best model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cU1FX4ZZR0uF",
        "colab_type": "code",
        "outputId": "d9452622-9892-4df0-9cc8-26293172e4ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd drive/My\\ Drive/hotel-recognition/src"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/hotel-recognition/src\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oENkQUVb7dJw",
        "colab_type": "text"
      },
      "source": [
        "More import:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qm_C61BwR365",
        "colab_type": "code",
        "outputId": "806a73b9-37da-4ad4-d47b-e3253b487ecc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import build_best_model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCAXWHcp8AYM",
        "colab_type": "text"
      },
      "source": [
        "Change back to the original directory:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPDwWBCMSG0p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(original_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FE-oUFj8DnG",
        "colab_type": "text"
      },
      "source": [
        "## Load and process the training images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOkeuPsL8QNL",
        "colab_type": "text"
      },
      "source": [
        "Change directory to load the training images:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8c65pfA3YuWA",
        "colab_type": "code",
        "outputId": "6264254f-fd01-47ff-ba08-1f0362a77e03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd drive/My\\ Drive/hotel-recognition/data/processed"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/hotel-recognition/data/processed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1K2QU3BM_mMn",
        "colab_type": "text"
      },
      "source": [
        "Load and process the training images and labels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gtjMPH8Zy4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# images\n",
        "training_images_batch_1 = pickle.load(open(\"training_images_batch_1.pickle\", \"rb\"))\n",
        "training_images_batch_2 = pickle.load(open(\"training_images_batch_2.pickle\", \"rb\"))\n",
        "training_images_batch_3 = pickle.load(open(\"training_images_batch_3.pickle\", \"rb\"))\n",
        "training_images_batch_4 = pickle.load(open(\"training_images_batch_4.pickle\", \"rb\"))\n",
        "training_images_batch_5 = pickle.load(open(\"training_images_batch_5.pickle\", \"rb\"))\n",
        "training_images_batch_6 = pickle.load(open(\"training_images_batch_6.pickle\", \"rb\"))\n",
        "training_images = np.concatenate((training_images_batch_1, training_images_batch_2, training_images_batch_3, training_images_batch_4, training_images_batch_5, training_images_batch_6))\n",
        "training_images = training_images * 1.0 / 255\n",
        "\n",
        "# labels\n",
        "training_labels = pickle.load(open(\"training_labels.pickle\", \"rb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcaTUMx18eCM",
        "colab_type": "text"
      },
      "source": [
        "Change back to the original directory:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7fYWwJ5iQLd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(original_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBomFGZR8fxc",
        "colab_type": "text"
      },
      "source": [
        "## Build and save the best model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFnFZFdG8p_b",
        "colab_type": "text"
      },
      "source": [
        "Change directory to save the best model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEqXla3hiW0-",
        "colab_type": "code",
        "outputId": "35782e4e-25f5-43bc-ad70-a2e8f3057161",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd drive/My\\ Drive/hotel-recognition/model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/hotel-recognition/models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCPwcvuTAEY-",
        "colab_type": "text"
      },
      "source": [
        "Build and save the best model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adJ38ACzR-jI",
        "colab_type": "code",
        "outputId": "271c0970-a08c-465c-9f8e-9a4a4f25adc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "build_best_model.build_best_model(training_images, training_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               4194816   \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 3)                 387       \n",
            "=================================================================\n",
            "Total params: 19,077,699\n",
            "Trainable params: 11,440,643\n",
            "Non-trainable params: 7,637,056\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 12000 samples, validate on 3000 samples\n",
            "Epoch 1/100\n",
            "12000/12000 [==============================] - 88s 7ms/step - loss: 1.1566 - acc: 0.5062 - val_loss: 0.8295 - val_acc: 0.6077\n",
            "Epoch 2/100\n",
            "12000/12000 [==============================] - 82s 7ms/step - loss: 0.7850 - acc: 0.6544 - val_loss: 1.0250 - val_acc: 0.5787\n",
            "Epoch 3/100\n",
            "12000/12000 [==============================] - 81s 7ms/step - loss: 0.7573 - acc: 0.6667 - val_loss: 1.0598 - val_acc: 0.5533\n",
            "Epoch 4/100\n",
            "12000/12000 [==============================] - 82s 7ms/step - loss: 0.6517 - acc: 0.7288 - val_loss: 0.8884 - val_acc: 0.6300\n",
            "Epoch 5/100\n",
            "12000/12000 [==============================] - 82s 7ms/step - loss: 0.5745 - acc: 0.7649 - val_loss: 0.7028 - val_acc: 0.6823\n",
            "Epoch 6/100\n",
            "12000/12000 [==============================] - 82s 7ms/step - loss: 0.5071 - acc: 0.7993 - val_loss: 0.7820 - val_acc: 0.6803\n",
            "Epoch 7/100\n",
            "12000/12000 [==============================] - 82s 7ms/step - loss: 0.4548 - acc: 0.8215 - val_loss: 1.0141 - val_acc: 0.6403\n",
            "Epoch 8/100\n",
            "12000/12000 [==============================] - 82s 7ms/step - loss: 0.3924 - acc: 0.8497 - val_loss: 0.6576 - val_acc: 0.7397\n",
            "Epoch 9/100\n",
            "12000/12000 [==============================] - 82s 7ms/step - loss: 0.3255 - acc: 0.8790 - val_loss: 0.6951 - val_acc: 0.7493\n",
            "Epoch 10/100\n",
            "12000/12000 [==============================] - 82s 7ms/step - loss: 0.2921 - acc: 0.8896 - val_loss: 0.7545 - val_acc: 0.7150\n",
            "Epoch 11/100\n",
            "12000/12000 [==============================] - 82s 7ms/step - loss: 0.2281 - acc: 0.9168 - val_loss: 0.7476 - val_acc: 0.7380\n",
            "Epoch 12/100\n",
            "12000/12000 [==============================] - 82s 7ms/step - loss: 0.1876 - acc: 0.9332 - val_loss: 0.7426 - val_acc: 0.7783\n",
            "Epoch 13/100\n",
            "12000/12000 [==============================] - 82s 7ms/step - loss: 0.1626 - acc: 0.9425 - val_loss: 0.8243 - val_acc: 0.7580\n",
            "Epoch 14/100\n",
            "12000/12000 [==============================] - 82s 7ms/step - loss: 0.1331 - acc: 0.9542 - val_loss: 0.8288 - val_acc: 0.7777\n",
            "Epoch 15/100\n",
            "12000/12000 [==============================] - 82s 7ms/step - loss: 0.1157 - acc: 0.9582 - val_loss: 0.8730 - val_acc: 0.7617\n",
            "Epoch 16/100\n",
            "12000/12000 [==============================] - 82s 7ms/step - loss: 0.1121 - acc: 0.9617 - val_loss: 5.5304 - val_acc: 0.5407\n",
            "Epoch 17/100\n",
            "12000/12000 [==============================] - 82s 7ms/step - loss: 0.0948 - acc: 0.9694 - val_loss: 0.9633 - val_acc: 0.7647\n",
            "Epoch 18/100\n",
            "12000/12000 [==============================] - 82s 7ms/step - loss: 0.1583 - acc: 0.9458 - val_loss: 1.0570 - val_acc: 0.7450\n",
            "Epoch 19/100\n",
            "12000/12000 [==============================] - 82s 7ms/step - loss: 0.1055 - acc: 0.9627 - val_loss: 0.9893 - val_acc: 0.7740\n",
            "Epoch 20/100\n",
            "12000/12000 [==============================] - 81s 7ms/step - loss: 0.0889 - acc: 0.9713 - val_loss: 0.9216 - val_acc: 0.7813\n",
            "Epoch 21/100\n",
            "12000/12000 [==============================] - 82s 7ms/step - loss: 0.0909 - acc: 0.9703 - val_loss: 0.8570 - val_acc: 0.7893\n",
            "Epoch 22/100\n",
            "12000/12000 [==============================] - 82s 7ms/step - loss: 0.0689 - acc: 0.9774 - val_loss: 0.9928 - val_acc: 0.7757\n",
            "Epoch 23/100\n",
            "12000/12000 [==============================] - 82s 7ms/step - loss: 0.0663 - acc: 0.9780 - val_loss: 0.9692 - val_acc: 0.7663\n",
            "Epoch 24/100\n",
            "12000/12000 [==============================] - 81s 7ms/step - loss: 0.0912 - acc: 0.9707 - val_loss: 1.0005 - val_acc: 0.7653\n",
            "Epoch 25/100\n",
            "12000/12000 [==============================] - 81s 7ms/step - loss: 0.0649 - acc: 0.9802 - val_loss: 1.1238 - val_acc: 0.7477\n",
            "Epoch 26/100\n",
            "12000/12000 [==============================] - 82s 7ms/step - loss: 0.0549 - acc: 0.9837 - val_loss: 0.9334 - val_acc: 0.7873\n",
            "Epoch 27/100\n",
            "12000/12000 [==============================] - 81s 7ms/step - loss: 0.0556 - acc: 0.9812 - val_loss: 0.9172 - val_acc: 0.8000\n",
            "Epoch 28/100\n",
            "12000/12000 [==============================] - 81s 7ms/step - loss: 0.0424 - acc: 0.9862 - val_loss: 1.2918 - val_acc: 0.7667\n",
            "Epoch 29/100\n",
            "12000/12000 [==============================] - 81s 7ms/step - loss: 0.0446 - acc: 0.9861 - val_loss: 1.1231 - val_acc: 0.7847\n",
            "Epoch 30/100\n",
            "12000/12000 [==============================] - 81s 7ms/step - loss: 0.0508 - acc: 0.9836 - val_loss: 1.1421 - val_acc: 0.7637\n",
            "Epoch 31/100\n",
            "12000/12000 [==============================] - 81s 7ms/step - loss: 0.0368 - acc: 0.9889 - val_loss: 1.2596 - val_acc: 0.7597\n",
            "Epoch 32/100\n",
            "12000/12000 [==============================] - 81s 7ms/step - loss: 0.0482 - acc: 0.9863 - val_loss: 1.3357 - val_acc: 0.7557\n",
            "Epoch 33/100\n",
            "12000/12000 [==============================] - 81s 7ms/step - loss: 0.0445 - acc: 0.9862 - val_loss: 1.0993 - val_acc: 0.7883\n",
            "Epoch 34/100\n",
            "12000/12000 [==============================] - 81s 7ms/step - loss: 0.0376 - acc: 0.9882 - val_loss: 1.1141 - val_acc: 0.7740\n",
            "Epoch 35/100\n",
            "12000/12000 [==============================] - 81s 7ms/step - loss: 0.0450 - acc: 0.9860 - val_loss: 0.9560 - val_acc: 0.7900\n",
            "Epoch 36/100\n",
            "12000/12000 [==============================] - 81s 7ms/step - loss: 0.0389 - acc: 0.9881 - val_loss: 1.1427 - val_acc: 0.7733\n",
            "Epoch 37/100\n",
            "12000/12000 [==============================] - 81s 7ms/step - loss: 0.0290 - acc: 0.9917 - val_loss: 1.1037 - val_acc: 0.7827\n",
            "Epoch 38/100\n",
            "12000/12000 [==============================] - 81s 7ms/step - loss: 0.0418 - acc: 0.9872 - val_loss: 1.0789 - val_acc: 0.7680\n",
            "Epoch 39/100\n",
            "12000/12000 [==============================] - 82s 7ms/step - loss: 0.0321 - acc: 0.9902 - val_loss: 1.0403 - val_acc: 0.7910\n",
            "Epoch 40/100\n",
            "12000/12000 [==============================] - 82s 7ms/step - loss: 0.0314 - acc: 0.9897 - val_loss: 1.0023 - val_acc: 0.7953\n",
            "Epoch 41/100\n",
            "12000/12000 [==============================] - 82s 7ms/step - loss: 0.0364 - acc: 0.9905 - val_loss: 0.9964 - val_acc: 0.7990\n",
            "Epoch 42/100\n",
            "12000/12000 [==============================] - 81s 7ms/step - loss: 0.0256 - acc: 0.9927 - val_loss: 1.2541 - val_acc: 0.7770\n",
            "Epoch 43/100\n",
            "12000/12000 [==============================] - 82s 7ms/step - loss: 0.0357 - acc: 0.9901 - val_loss: 1.3112 - val_acc: 0.7473\n",
            "Epoch 44/100\n",
            "12000/12000 [==============================] - 82s 7ms/step - loss: 0.0303 - acc: 0.9911 - val_loss: 1.0453 - val_acc: 0.7977\n",
            "Epoch 45/100\n",
            "12000/12000 [==============================] - 81s 7ms/step - loss: 0.0213 - acc: 0.9936 - val_loss: 1.3606 - val_acc: 0.7493\n",
            "Epoch 46/100\n",
            "12000/12000 [==============================] - 82s 7ms/step - loss: 0.0206 - acc: 0.9938 - val_loss: 1.1113 - val_acc: 0.8010\n",
            "Epoch 47/100\n",
            "12000/12000 [==============================] - 81s 7ms/step - loss: 0.0310 - acc: 0.9906 - val_loss: 1.0175 - val_acc: 0.7817\n",
            "Epoch 48/100\n",
            "12000/12000 [==============================] - 81s 7ms/step - loss: 0.0169 - acc: 0.9946 - val_loss: 1.1421 - val_acc: 0.7940\n",
            "Epoch 49/100\n",
            "12000/12000 [==============================] - 81s 7ms/step - loss: 0.0267 - acc: 0.9917 - val_loss: 0.9825 - val_acc: 0.7927\n",
            "Epoch 50/100\n",
            "12000/12000 [==============================] - 81s 7ms/step - loss: 0.0159 - acc: 0.9951 - val_loss: 1.2141 - val_acc: 0.7987\n",
            "Epoch 51/100\n",
            "12000/12000 [==============================] - 81s 7ms/step - loss: 0.0302 - acc: 0.9917 - val_loss: 1.0162 - val_acc: 0.7927\n",
            "Epoch 52/100\n",
            "12000/12000 [==============================] - 81s 7ms/step - loss: 0.0156 - acc: 0.9951 - val_loss: 1.0639 - val_acc: 0.7897\n",
            "Epoch 53/100\n",
            "12000/12000 [==============================] - 81s 7ms/step - loss: 0.0156 - acc: 0.9953 - val_loss: 1.1633 - val_acc: 0.7930\n",
            "Epoch 54/100\n",
            "12000/12000 [==============================] - 81s 7ms/step - loss: 0.0183 - acc: 0.9942 - val_loss: 1.1779 - val_acc: 0.7947\n",
            "Epoch 55/100\n",
            "12000/12000 [==============================] - 81s 7ms/step - loss: 0.0217 - acc: 0.9934 - val_loss: 1.1672 - val_acc: 0.7723\n",
            "Epoch 56/100\n",
            "12000/12000 [==============================] - 81s 7ms/step - loss: 0.0162 - acc: 0.9947 - val_loss: 1.1077 - val_acc: 0.7910\n",
            "Epoch 57/100\n",
            "12000/12000 [==============================] - 81s 7ms/step - loss: 0.0192 - acc: 0.9938 - val_loss: 1.1547 - val_acc: 0.7850\n",
            "Epoch 58/100\n",
            "12000/12000 [==============================] - 81s 7ms/step - loss: 0.0178 - acc: 0.9951 - val_loss: 1.1376 - val_acc: 0.7913\n",
            "Epoch 59/100\n",
            "12000/12000 [==============================] - 81s 7ms/step - loss: 0.0250 - acc: 0.9923 - val_loss: 1.1537 - val_acc: 0.7717\n",
            "Epoch 60/100\n",
            "12000/12000 [==============================] - 81s 7ms/step - loss: 0.0172 - acc: 0.9960 - val_loss: 1.1678 - val_acc: 0.7883\n",
            "Epoch 61/100\n",
            "12000/12000 [==============================] - 81s 7ms/step - loss: 0.0151 - acc: 0.9955 - val_loss: 1.0974 - val_acc: 0.7900\n",
            "Epoch 62/100\n",
            "12000/12000 [==============================] - 81s 7ms/step - loss: 0.0190 - acc: 0.9952 - val_loss: 1.1065 - val_acc: 0.7980\n",
            "Epoch 63/100\n",
            "12000/12000 [==============================] - 81s 7ms/step - loss: 0.0284 - acc: 0.9930 - val_loss: 0.9842 - val_acc: 0.7910\n",
            "Epoch 64/100\n",
            "12000/12000 [==============================] - 81s 7ms/step - loss: 0.0118 - acc: 0.9967 - val_loss: 1.1237 - val_acc: 0.7857\n",
            "Epoch 65/100\n",
            "12000/12000 [==============================] - 81s 7ms/step - loss: 0.0228 - acc: 0.9929 - val_loss: 1.2269 - val_acc: 0.7870\n",
            "Epoch 66/100\n",
            "12000/12000 [==============================] - 81s 7ms/step - loss: 0.0171 - acc: 0.9955 - val_loss: 1.1137 - val_acc: 0.7950\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTRzqeKt8zWB",
        "colab_type": "text"
      },
      "source": [
        "Change back to the original directory:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3KTnJpGimw6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(original_path)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}